{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load files\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique label count\n",
    "print ('The train data has {} unique labels'.format(train['label'].nunique()))\n",
    "#Labels \n",
    "label_counts = train['label'].value_counts()\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.barplot(label_counts.index, label_counts.values, alpha = 0.9)\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.xlabel('Image Labels', fontsize =12)\n",
    "plt.ylabel('Counts', fontsize = 12)\n",
    "plt.show()\n",
    "print(type(label_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to read train and test image\n",
    "TRAIN_PATH = '../data/train_img/'\n",
    "TEST_PATH = '../data/test_img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read images as arrays\n",
    "def read_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    #Image is loaded as BGR convert it to RGB.\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (64,64)) # you can resize to  (128,128) or (256,256)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "train_labels = train['label'].values\n",
    "\n",
    "for img in tqdm(train['image_id'].values):\n",
    "    train_data.append(read_image(TRAIN_PATH + '{}.png'.format(img)))\n",
    "    \n",
    "for img in tqdm(test['image_id'].values):\n",
    "    test_data.append(read_image(TEST_PATH + '{}.png'.format(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now you have list of images\n",
    "print(type(train_data))\n",
    "#Convert them to numpy float arrays in passion(b,h,w,c) and normalize them too.\n",
    "x_train = np.array(train_data, np.float32) / 255.\n",
    "x_test = np.array(test_data, np.float32) / 255.\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable - encoding numeric value\n",
    "label_list = train['label'].tolist()\n",
    "Y_train = {k:v for v,k in enumerate(set(label_list))}\n",
    "print(type(Y_train))\n",
    "categories = len(Y_train)\n",
    "print('categories',categories)\n",
    "print(Y_train)\n",
    "y_train1 =np.array([Y_train[k] for k in label_list])\n",
    "print(y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## just images doesn't help, lets see the images with their respective labels\n",
    "plt.rc('axes', grid=False)\n",
    "\n",
    "_, axs = plt.subplots(3,3, sharex = 'col', sharey='row', figsize = (7,7))\n",
    "axs = axs.ravel()\n",
    "\n",
    "# lets see first 8 images - you can increase i value to see more images\n",
    "for i, (image_name, label) in enumerate(zip(train.image_id, train.label)):\n",
    "    if i <= 8:\n",
    "        img = read_image(TRAIN_PATH + image_name + '.png')\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].set_title('{} - {}'.format(image_name, label))\n",
    "    else:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to one-hot\n",
    "def one_hot(a, num_classes):\n",
    "  return np.squeeze(np.eye(num_classes)[a.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = one_hot(y_train1,categories)\n",
    "print (\"number of training examples = \" + str(x_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(x_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(x_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_test shape: \" + str(x_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils import *\n",
    "#utils contain a simple tensorflow template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Placeholders followed by Tensorflow\n",
    "#x = tf.placeholder(tf.float32, shape=[None, 64*64], name='X')\n",
    "# Reshape it into [num_images, img_height, img_width, num_channels]\n",
    "x_image = tf.placeholder(tf.float32, shape=[None, 64, 64, 3], name='X')\n",
    "\n",
    "# Placeholder variable for the true labels associated with the images\n",
    "y_actual = tf.placeholder(tf.float32, shape=[None, 25], name='y_actual')\n",
    "y_actual_cls = tf.argmax(y_actual, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph Started\n",
    "layer_conv1, weights_conv1 = new_conv_layer(input=x_image, num_input_channels=3, filter_size=3, num_filters=32, name =\"conv1\")\n",
    "layer_pool1 = new_pool_layer(layer_conv1, name=\"pool1\")\n",
    "layer_relu1 = new_relu_layer(layer_pool1, name=\"relu1\")\n",
    "\n",
    "layer_conv2, weights_conv2 = new_conv_layer(input=layer_relu1, num_input_channels=32, filter_size=3, num_filters=64, name= \"conv2\")\n",
    "layer_pool2 = new_pool_layer(layer_conv2, name=\"pool2\")\n",
    "layer_relu2 = new_relu_layer(layer_pool2, name=\"relu2\")\n",
    "\n",
    "layer_conv3, weights_conv3 = new_conv_layer(input=layer_relu2, num_input_channels=64, filter_size=3, num_filters=128, name= \"conv3\")\n",
    "layer_pool3 = new_pool_layer(layer_conv3, name=\"pool3\")\n",
    "layer_relu3 = new_relu_layer(layer_pool3, name=\"relu3\")\n",
    "\n",
    "layer_conv4, weights_conv4 = new_conv_layer(input=layer_relu3, num_input_channels=128, filter_size=3, num_filters=256, name= \"conv4\")\n",
    "layer_pool4 = new_pool_layer(layer_conv4, name=\"pool4\")\n",
    "layer_relu4 = new_relu_layer(layer_pool4, name=\"relu4\")\n",
    "\n",
    "num_features = layer_relu4.get_shape()[1:4].num_elements()\n",
    "layer_flat = tf.reshape(layer_relu4, [-1, num_features])\n",
    "layer_fc1 = new_fc_layer(layer_flat, num_inputs=num_features, num_outputs=128, name=\"fc1\")\n",
    "layer_relu5 = new_relu_layer(layer_fc1, name=\"relu5\")\n",
    "layer_fc2 = new_fc_layer(input=layer_relu5, num_inputs=128, num_outputs=25, name=\"fc2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we have 25 values in the last computed layer\n",
    "# Use Softmax function to normalize the output\n",
    "with tf.variable_scope(\"Softmax\"):\n",
    "    y_pred = tf.nn.softmax(layer_fc2)\n",
    "    y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cross entropy cost function\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_actual)#logits = layer_fc2\n",
    "    cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Adam Optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(y_pred_cls, y_actual_cls)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few\n",
    "num_epochs = 100\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(\"Training_FileWriter/\")\n",
    "writer1 = tf.summary.FileWriter(\"Validation_FileWriter/\")\n",
    "# Add the cost and accuracy to summary\n",
    "tf.summary.scalar('loss', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer.add_graph(sess.graph)\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        train_accuracy = 0\n",
    "        train_cost = 0\n",
    "        beg, end = 0, batch_size\n",
    "        for batch in range(0, x_train.shape[0]/batch_size):\n",
    "             x_batch = x_train[beg:end]\n",
    "             y_actual_batch = y_train[beg:end]\n",
    "             beg = end\n",
    "             end = end+batch_size\n",
    "             #print x_batch.shape, y_true_batch.shape\n",
    "             # Put the batch into a dict with the proper names for placeholder variables\n",
    "             feed_dict_train = {x_image: x_batch, y_actual: y_actual_batch}\n",
    "             # Run the optimizer using this batch of training data.\n",
    "             sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "             # Calculate the accuracy on the batch of training data\n",
    "             train_accuracy += sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "             train_cost += sess.run(cost, feed_dict=feed_dict_train)\n",
    "            \n",
    "        train_accuracy /= int(x_train.shape[0])/batch_size\n",
    "        train_cost /= int(x_train.shape[0])/batch_size\n",
    "        # Generate summary and validate the model on the entire validation set\n",
    "        summ, vali_accuracy = sess.run([merged_summary, accuracy], feed_dict={x_image:x_train[0:20], y_actual:y_train[0:20]})\n",
    "        writer1.add_summary(summ, epoch)\n",
    "        \n",
    "\n",
    "        end_time = time.time()\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Epoch \"+str(epoch+1)+\" completed : Time usage \"+str(int(end_time-start_time))+\" seconds\")\n",
    "        print(\"\\tAccuracy:\")\n",
    "        print (\"\\t- Training Accuracy:\\t{}\".format(train_accuracy))\n",
    "        print (\"\\t- Validation Accuracy:\\t{}\".format(vali_accuracy))\n",
    "        print (\"\\t- Training Cost:\\t{}\".format(train_cost))\n",
    "        \n",
    "        predictions = sess.run(y_pred_cls,feed_dict={x_image: x_test})\n",
    "#         predictions = np.argmax(predictions, axis= 1)\n",
    "        y_maps = dict()\n",
    "        y_maps = {v:k for k, v in Y_train.items()}\n",
    "        pred_labels = [y_maps[k] for k in predictions]\n",
    "        sub1 = pd.DataFrame({'image_id':test.image_id, 'label':pred_labels})\n",
    "        sub1.to_csv('./results/sub_'+str(epoch)+'.csv', index=False)\n",
    "        print('Written CSV!')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
